{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loose inspiration from: https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "\n",
    "\n",
    "# From a corpus of midi files, generate tokens for a sequence model\n",
    "\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from music21.midi import MidiException\n",
    "from random import shuffle\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import sys\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "\n",
    "# Instruments to look for\n",
    "instr = (instrument.Piano, instrument.StringInstrument, instrument.Harpsichord)\n",
    "\n",
    "# Ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "# Custom exception class for time-out\n",
    "class TimeoutException(Exception):   \n",
    "    pass\n",
    "\n",
    "# Custom signal handler\n",
    "def timeout_handler(signum, frame):   \n",
    "    raise TimeoutException\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "\n",
    "# Tokenize midis in source_dir for training sequence model\n",
    "def tokenize_midis(source_dir, dest_file, timeout=30, monophonic=False, rests=False, durations=False, \n",
    "                   instr = (instrument.Piano, instrument.StringInstrument, instrument.Harpsichord)):\n",
    "    \n",
    "    # Iterate over midis in directory\n",
    "    midi_list = glob.glob(source_dir + '/**/*.mid', recursive=True)\n",
    "    shuffle(midi_list)\n",
    "    \n",
    "    total = len(midi_list)\n",
    "    i = 1\n",
    "    outfile = open(dest_file, 'w')\n",
    "    \n",
    "    for file in midi_list:\n",
    "        tokens = []\n",
    "        \n",
    "        # Set time-out alarm (seconds) in case transposing is taking too long\n",
    "        signal.alarm(timeout)\n",
    "        \n",
    "        # Try to parse the file\n",
    "        try:\n",
    "            s1 = converter.parse(file)\n",
    "            notes_to_parse = None\n",
    "            \n",
    "            # If flat file\n",
    "            if len(s1.parts) == 1:\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.flat.notes\n",
    "                else:\n",
    "                    notes_to_parse = s1.flat.notes.chordify()\n",
    "            \n",
    "            # If file has parts matching desired instruments\n",
    "            elif any(isinstance(part.getInstrument(), instr) for part in s1.parts):\n",
    "                for part in s1.parts:\n",
    "                    if not isinstance(part.getInstrument(), instr):\n",
    "                        s1.remove(part)\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.parts[0]\n",
    "                else:\n",
    "                    notes_to_parse = s1.parts.chordify()\n",
    "                \n",
    "            # If no matching parts, try first one\n",
    "            else:\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.parts[0]\n",
    "                else:\n",
    "                    notes_to_parse = s1.parts[0].chordify()\n",
    "                \n",
    "            # Perform tokenization\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    if durations:\n",
    "                        tokens.append(str(element.pitch)+'.'+str(element.duration.type))\n",
    "                    else:\n",
    "                        tokens.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    if monophonic:\n",
    "                        if durations:\n",
    "                            tokens.append(element.root().name + str(element.root().octave) + '.' + str(element.duration.type))\n",
    "                        else:\n",
    "                            tokens.append(element.root().name + str(element.root().octave))\n",
    "                    else:\n",
    "                        if durations:\n",
    "                            tokens.append('.'.join((pitch.name + str(pitch.octave)) for pitch in element.pitches)+'.'+str(element.duration.type))\n",
    "                        else:\n",
    "                            tokens.append('.'.join((pitch.name + str(pitch.octave)) for pitch in element.pitches))\n",
    "                elif isinstance(element, note.Rest):\n",
    "                    if rests:\n",
    "                        tokens.append('rest')\n",
    "        \n",
    "        # Tokenizing took too long\n",
    "        except TimeoutException:\n",
    "            print(\"Time-out tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        \n",
    "        # Tokenizing encountered an error\n",
    "        except (MidiException, IndexError, TypeError):\n",
    "            print(\"Exception tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            signal.alarm(0)\n",
    "            print(\"Tokenized file\", i, \"out of\", total)\n",
    "            \n",
    "        finally:\n",
    "            i += 1\n",
    "        \n",
    "        outfile.write(\" \".join(tokens)+\"\\n\")\n",
    "        \n",
    "    outfile.close()\n",
    "    print('Tokens written to %s' % dest_file)\n",
    "    print('Vocabulary size is %i' % len(set(w for w in open(dest_file).read().split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_midis('./testmids/', './testmids/testtokens.txt', monophonic=True)\n",
    "tokenize_midis('./testmids/', './testmids/testtokens2.txt', durations=True)\n",
    "print('Tokenize original complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
